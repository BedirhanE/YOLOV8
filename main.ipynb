{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bedir\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import time \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu kÄ±sÄ±mda, Ultralytics YOLO modelini ve OpenCV kÃ¼tÃ¼phanesini kullanmak iÃ§in gerekli modÃ¼lleri iÃ§e aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 720)\n",
    "cap.set(4, 720)\n",
    "\n",
    "while True:\n",
    "    ret, img= cap.read()\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('b'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web kameranÄ±zÄ± aÃ§mak iÃ§in OpenCV'nin VideoCapture sÄ±nÄ±fÄ±nÄ± kullanÄ±yoruz. Bu kÄ±sÄ±mda, kamera numarasÄ±nÄ± (0 genellikle bilgisayarÄ±n yerleÅŸik kamerasÄ±nÄ± temsil eder), geniÅŸlik ve yÃ¼kseklik deÄŸerlerini ayarlÄ±yoruz.\n",
    "\n",
    "Bu dÃ¶ngÃ¼, kameradan gelen gÃ¶rÃ¼ntÃ¼yÃ¼ sÃ¼rekli olarak okur ve ekranda gÃ¶rÃ¼ntÃ¼ler. EÄŸer kullanÄ±cÄ± 'b' tuÅŸuna basarsa, dÃ¶ngÃ¼den Ã§Ä±kÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultralytics YOLO modelini baÅŸlatmak iÃ§in gerekli sÄ±nÄ±fÄ± ve Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ± yÃ¼klÃ¼yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO V8 EÄžÄ°TÄ°LMÄ°Åž MODEL Ä°LE OBJECT DETECTÄ°ON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP ðŸ’¡ Replace 'model=yolo-Weights/yolov3.pt' with new 'model=yolo-Weights/yolov3u.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 6.8ms preprocess, 149.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 127.8ms\n",
      "Speed: 1.3ms preprocess, 127.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 0.0ms preprocess, 107.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 113.1ms\n",
      "Speed: 0.0ms preprocess, 113.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 210.3ms\n",
      "Speed: 2.5ms preprocess, 210.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 204.7ms\n",
      "Speed: 2.5ms preprocess, 204.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 227.3ms\n",
      "Speed: 2.7ms preprocess, 227.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 212.2ms\n",
      "Speed: 1.8ms preprocess, 212.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "mode3 = YOLO(\"yolo-Weights/yolov3.pt\")\n",
    "\n",
    "# object classes\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes: #Modelin Ã§Ä±kÄ±ÅŸÄ± iÃ§indeki kutulara (bounding boxes) eriÅŸiyoruz.\n",
    "            \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            \n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)  #AlgÄ±lama gÃ¼venini hesaplayÄ±p ekrana yazdÄ±rÄ±yoruz\n",
    "\n",
    "            \n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # AlgÄ±lanan nesnenin sÄ±nÄ±fÄ±nÄ± alÄ±p, sÄ±nÄ±f adÄ±nÄ± ekrana yazdÄ±rÄ±yoruz.\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 236.6ms\n",
      "Speed: 1.1ms preprocess, 236.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 230.1ms\n",
      "Speed: 10.5ms preprocess, 230.1ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 225.1ms\n",
      "Speed: 0.0ms preprocess, 225.1ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 114.0ms\n",
      "Speed: 2.0ms preprocess, 114.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 117.8ms\n",
      "Speed: 0.0ms preprocess, 117.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 114.2ms\n",
      "Speed: 2.5ms preprocess, 114.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 105.3ms\n",
      "Speed: 2.8ms preprocess, 105.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 117.6ms\n",
      "Speed: 0.0ms preprocess, 117.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 120.0ms\n",
      "Speed: 2.1ms preprocess, 120.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 119.4ms\n",
      "Speed: 0.6ms preprocess, 119.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 104.5ms\n",
      "Speed: 2.4ms preprocess, 104.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 98.4ms\n",
      "Speed: 0.0ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 109.7ms\n",
      "Speed: 0.0ms preprocess, 109.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 116.8ms\n",
      "Speed: 0.3ms preprocess, 116.8ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 208.2ms\n",
      "Speed: 0.0ms preprocess, 208.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 223.2ms\n",
      "Speed: 0.0ms preprocess, 223.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 207.2ms\n",
      "Speed: 0.0ms preprocess, 207.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 221.7ms\n",
      "Speed: 0.0ms preprocess, 221.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 230.2ms\n",
      "Speed: 0.0ms preprocess, 230.2ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 227.7ms\n",
      "Speed: 0.0ms preprocess, 227.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 133.1ms\n",
      "Speed: 2.0ms preprocess, 133.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 110.5ms\n",
      "Speed: 0.0ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "0: 480x640 2 persons, 116.2ms\n",
      "Speed: 0.0ms preprocess, 116.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> refrigerator\n",
      "0: 480x640 1 person, 1 refrigerator, 100.9ms\n",
      "Speed: 0.0ms preprocess, 100.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> refrigerator\n",
      "0: 480x640 1 person, 1 refrigerator, 112.1ms\n",
      "Speed: 0.0ms preprocess, 112.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 115.5ms\n",
      "Speed: 1.5ms preprocess, 115.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 111.9ms\n",
      "Speed: 0.1ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 107.1ms\n",
      "Speed: 2.0ms preprocess, 107.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 107.9ms\n",
      "Speed: 2.0ms preprocess, 107.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 116.9ms\n",
      "Speed: 2.1ms preprocess, 116.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 107.9ms\n",
      "Speed: 0.5ms preprocess, 107.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 165.4ms\n",
      "Speed: 2.1ms preprocess, 165.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 219.7ms\n",
      "Speed: 0.0ms preprocess, 219.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "0: 480x640 1 person, 195.2ms\n",
      "Speed: 0.0ms preprocess, 195.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "\n",
    "# Web kamerayÄ± baÅŸlat\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# YOLO modelini baÅŸlat\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Nesne sÄ±nÄ±flarÄ±\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # AlgÄ±lanan nesnenin bounding box'Ä±nÄ± Ã§iz\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # AlgÄ±lama gÃ¼venini hesapla\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\", confidence)\n",
    "\n",
    "            # AlgÄ±lanan sÄ±nÄ±fÄ±n adÄ±nÄ± al\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # AlgÄ±lanan nesnenin sÄ±nÄ±f adÄ±nÄ± ve gÃ¼venini ekrana yazdÄ±r\n",
    "            text = f\"{classNames[cls]}: {confidence:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(img, text, org, font, fontScale, color, thickness)\n",
    "\n",
    "    # GÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶ster\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # 'q' tuÅŸuna basÄ±ldÄ±ÄŸÄ±nda dÃ¶ngÃ¼den Ã§Ä±k\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# KamerayÄ± serbest bÄ±rak ve OpenCV penceresini kapat\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# USB kamerasÄ±nÄ± baÅŸlat\n",
    "usb_kamera = cv2.VideoCapture(0,cv2.CAP_DSHOW)  # \"0\" genellikle bilgisayara baÄŸlÄ± birinci kamera demektir\n",
    "\n",
    "# Kamera Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼nÃ¼ ayarla\n",
    "usb_kamera.set(3, 640)\n",
    "usb_kamera.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    # USB kameradan gÃ¶rÃ¼ntÃ¼ al\n",
    "    basari, resim = usb_kamera.read()\n",
    "\n",
    "    # GÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶ster\n",
    "    cv2.imshow('USB Kamera', resim)\n",
    "\n",
    "    # 'q' tuÅŸuna basÄ±ldÄ±ÄŸÄ±nda dÃ¶ngÃ¼den Ã§Ä±k\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# KamerayÄ± serbest bÄ±rak ve OpenCV penceresini kapat\n",
    "usb_kamera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#video yu baÅŸlatma iÅŸlemi\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)  #0 bilgisayara baÄŸlÄ± birinci kamera 1 harici diÄŸer kamerayÄ± temsil ediyor.\n",
    "\n",
    "while True:\n",
    "    # kameradan gÃ¶rÃ¼ntÃ¼ alma iÅŸlemi\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # kamera baÄŸlantÄ±sÄ±nÄ±n baÅŸarÄ±sÄ±z olup olmadÄ±ÄŸÄ±nÄ± kontrol etme iÅŸlemi\n",
    "    if not ret:\n",
    "        print(\"Kamera baÄŸlantÄ±sÄ± baÅŸarÄ±sÄ±z.\")\n",
    "        break\n",
    "\n",
    "    # gÃ¶rÃ¼ntÃ¼yÃ¼ ekranda gÃ¶sterme iÅŸlemi\n",
    "    cv2.imshow('Kamera', frame)\n",
    "\n",
    "    # 'q' tuÅŸuna basÄ±ldÄ±ÄŸÄ±nda dÃ¶ngÃ¼yÃ¼ kÄ±rÄ±n\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#pencereyi kapatma iÅŸlemi\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Telefon ve harici kamera baÄŸlantÄ±sÄ± ile farklÄ± ekran baÄŸlantÄ±larÄ± ile object detection iÅŸlemi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "pc_kamera = cv2.VideoCapture(0)\n",
    "pc_kamera.set(3, 640)\n",
    "pc_kamera.set(4, 480)\n",
    "\n",
    "# Telefon kamerasÄ±nÄ± baÅŸlatma ve Ä±p ye gÃ¶re baÄŸlanma adÄ±mÄ± \n",
    "\n",
    "telefon_kamera_adresi = \"http://172.16.3.109:8080/video\"  \n",
    "telefon_kamera= cv2.VideoCapture(telefon_kamera_adresi)\n",
    "\n",
    "#logitech_camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "#hazÄ±r eÄŸitilmiÅŸ yolo modelim\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "sinif_isimleri = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                  \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                  \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                  \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                  \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                  \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                  \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                  \"teddy bear\", \"hair drier\", \"toothbrush\"] \n",
    "\n",
    "#kameralarÄ±n fps lerini gÃ¶sterme kÄ±smÄ± \n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    #laptopumdan gÃ¶rÃ¼ntÃ¼ alma \n",
    "    pc_basari, pc_resim = pc_kamera.read()\n",
    "    pc_sonuclar = model(pc_resim, stream=True)\n",
    "\n",
    "    for r in pc_sonuclar:\n",
    "        pc_kutular = r.boxes\n",
    "\n",
    "        for pc_kutu in pc_kutular:\n",
    "            x1, y1, x2, y2 = pc_kutu.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "           \n",
    "            cv2.rectangle(pc_resim, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            \n",
    "            guven = math.ceil((pc_kutu.conf[0] * 100)) / 100\n",
    "            print(\"GÃ¼ven --->\", guven)\n",
    "\n",
    "           \n",
    "            sinif = int(pc_kutu.cls[0])\n",
    "            print(\"SÄ±nÄ±f adÄ± -->\", sinif_isimleri[sinif])\n",
    "\n",
    "            \n",
    "            metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontOlcek = 0.5\n",
    "            renk = (255, 0, 0)\n",
    "            kalinlik = 1\n",
    "\n",
    "            cv2.putText(pc_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "   \n",
    "    telefon_basari, telefon_resim = telefon_kamera.read()\n",
    "\n",
    "   \n",
    "    if telefon_basari:\n",
    "        # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±nÄ± eÅŸitleme kÄ±sÄ±mÄ±\n",
    "        telefon_resim = cv2.resize(telefon_resim, (pc_resim.shape[1], pc_resim.shape[0]))\n",
    "\n",
    "        #GÃ¶rÃ¼ntÃ¼leri birleÅŸtirme iÅŸlemi\n",
    "        birlesik_resim = cv2.hconcat([pc_resim, telefon_resim])\n",
    "\n",
    "       \n",
    "        telefon_sonuclar = model(telefon_resim, stream=True)\n",
    "\n",
    "        for r in telefon_sonuclar:\n",
    "            telefon_kutular = r.boxes\n",
    "\n",
    "            for telefon_kutu in telefon_kutular:\n",
    "                x1, y1, x2, y2 = telefon_kutu.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                \n",
    "                cv2.rectangle(birlesik_resim, (x1 + pc_resim.shape[1], y1), (x2 + pc_resim.shape[1], y2), (255, 0, 255), 3)\n",
    "\n",
    "                \n",
    "                guven = math.ceil((telefon_kutu.conf[0] * 100)) / 100\n",
    "                print(\"GÃ¼ven (Telefon) --->\", guven)\n",
    "\n",
    "                \n",
    "                sinif = int(telefon_kutu.cls[0])\n",
    "                print(\"SÄ±nÄ±f adÄ± (Telefon) -->\", sinif_isimleri[sinif])\n",
    "\n",
    "                \n",
    "                metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "                org = (x1 + pc_resim.shape[1], y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontOlcek = 0.5\n",
    "                renk = (255, 0, 0)\n",
    "                kalinlik = 1\n",
    "\n",
    "                cv2.putText(birlesik_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "        \n",
    "        cv2.imshow('Bilgisayar ve Telefon KamerasÄ±', birlesik_resim)\n",
    "    else:\n",
    "        print(\"Telefon kamerasÄ±ndan gÃ¶rÃ¼ntÃ¼ alÄ±namadÄ±.\")\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "pc_kamera.release()\n",
    "telefon_kamera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPS DEÄžERLERÄ° EKLENMÄ°Åž HALÄ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GÃ¼ven ---> 0.9\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 276.3ms\n",
      "Speed: 7.0ms preprocess, 276.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.9\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 97.8ms\n",
      "Speed: 3.0ms preprocess, 97.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.91\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 123.7ms\n",
      "Speed: 1.0ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.91\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 113.7ms\n",
      "Speed: 1.9ms preprocess, 113.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.92\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 112.7ms\n",
      "Speed: 1.0ms preprocess, 112.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.92\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 115.7ms\n",
      "Speed: 3.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.91\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 120.7ms\n",
      "Speed: 2.0ms preprocess, 120.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.91\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 101.7ms\n",
      "Speed: 2.0ms preprocess, 101.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.91\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 106.7ms\n",
      "Speed: 2.0ms preprocess, 106.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.91\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 112.7ms\n",
      "Speed: 2.0ms preprocess, 112.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.91\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 102.7ms\n",
      "Speed: 1.0ms preprocess, 102.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.91\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 113.7ms\n",
      "Speed: 2.0ms preprocess, 113.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven ---> 0.91\n",
      "SÄ±nÄ±f adÄ± --> person\n",
      "0: 480x640 1 person, 105.7ms\n",
      "Speed: 2.0ms preprocess, 105.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "GÃ¼ven (Telefon) ---> 0.91\n",
      "SÄ±nÄ±f adÄ± (Telefon) --> person\n",
      "0: 480x640 1 person, 109.7ms\n",
      "Speed: 2.0ms preprocess, 109.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "\n",
    "\n",
    "pc_kamera = cv2.VideoCapture(0)\n",
    "pc_kamera.set(3, 640)\n",
    "pc_kamera.set(4, 480)\n",
    "\n",
    "# Telefon kamerasÄ±nÄ± baÅŸlatma ve Ä±p ye gÃ¶re baÄŸlanma adÄ±mÄ± \n",
    "\n",
    "# telefon_kamera_adresi = \"http://172.16.3.109:8080/video\"\n",
    "\n",
    "#cv2.VideoCapture(0,cv2.CAP_DSHOW) #Bekleme sÃ¼resini azaltmak iÃ§in \n",
    " \n",
    "\n",
    "logitech_camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "# hazÄ±r eÄŸitilmiÅŸ yolo modelim\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "sinif_isimleri = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                  \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                  \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                  \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                  \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                  \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                  \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                  \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Initialize variables for fps calculation\n",
    "start_time_pc = datetime.now()\n",
    "start_time_telefon = datetime.now()\n",
    "fps_pc = 0\n",
    "fps_telefon = 0\n",
    "\n",
    "while True:\n",
    "    # laptopumdan gÃ¶rÃ¼ntÃ¼ alma\n",
    "    pc_basari, pc_resim = pc_kamera.read()\n",
    "    pc_sonuclar = model(pc_resim, stream=True)\n",
    "\n",
    "    for r in pc_sonuclar:\n",
    "        pc_kutular = r.boxes\n",
    "\n",
    "        for pc_kutu in pc_kutular:\n",
    "            x1, y1, x2, y2 = pc_kutu.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            cv2.rectangle(pc_resim, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            guven = math.ceil((pc_kutu.conf[0] * 100)) / 100\n",
    "            print(\"GÃ¼ven --->\", guven)\n",
    "\n",
    "            sinif = int(pc_kutu.cls[0])\n",
    "            print(\"SÄ±nÄ±f adÄ± -->\", sinif_isimleri[sinif])\n",
    "\n",
    "            metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontOlcek = 0.5\n",
    "            renk = (255, 0, 0)\n",
    "            kalinlik = 1\n",
    "\n",
    "            cv2.putText(pc_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "    telefon_basari, telefon_resim = logitech_camera.read()\n",
    "\n",
    "    if telefon_basari:\n",
    "        \n",
    "        # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±nÄ± eÅŸitleme kÄ±sÄ±mÄ±\n",
    "        telefon_resim = cv2.resize(telefon_resim, (pc_resim.shape[1], pc_resim.shape[0]))\n",
    "\n",
    "        # GÃ¶rÃ¼ntÃ¼leri birleÅŸtirme iÅŸlemi\n",
    "        birlesik_resim = cv2.hconcat([pc_resim, telefon_resim])\n",
    "\n",
    "        telefon_sonuclar = model(telefon_resim, stream=True)\n",
    "\n",
    "        for r in telefon_sonuclar:\n",
    "            telefon_kutular = r.boxes\n",
    "\n",
    "            for telefon_kutu in telefon_kutular:\n",
    "                x1, y1, x2, y2 = telefon_kutu.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(birlesik_resim, (x1 + pc_resim.shape[1], y1), (x2 + pc_resim.shape[1], y2), (255, 0, 255), 3)\n",
    "\n",
    "                guven = math.ceil((telefon_kutu.conf[0] * 100)) / 100\n",
    "                print(\"GÃ¼ven (Telefon) --->\", guven)\n",
    "\n",
    "                sinif = int(telefon_kutu.cls[0])\n",
    "                print(\"SÄ±nÄ±f adÄ± (Telefon) -->\", sinif_isimleri[sinif])\n",
    "\n",
    "                metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "                org = (x1 + pc_resim.shape[1], y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontOlcek = 0.5\n",
    "                renk = (255, 0, 0)\n",
    "                kalinlik = 1\n",
    "\n",
    "                cv2.putText(birlesik_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "        # laptop ve kamera fps Ã¶lÃ§me \n",
    "        fps_pc = 1 / (datetime.now() - start_time_pc).total_seconds()\n",
    "        start_time_pc = datetime.now()\n",
    "\n",
    "        # fps deÄŸerlerini pencere ekranlÅŸarÄ±nda gÃ¶sterme \n",
    "        cv2.putText(birlesik_resim, f\"FPS (PC): {fps_pc:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        \n",
    "        fps_telefon = 1 / (datetime.now() - start_time_telefon).total_seconds()\n",
    "        start_time_telefon = datetime.now()\n",
    "\n",
    "        \n",
    "        cv2.putText(birlesik_resim, f\"FPS (Logitech_camera): {fps_telefon:.2f}\", (10 + pc_resim.shape[1], 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "       \n",
    "        cv2.imshow('Bilgisayar ve Telefon KamerasÄ±', birlesik_resim)\n",
    "    else:\n",
    "        print(\"Telefon kamerasÄ±ndan gÃ¶rÃ¼ntÃ¼ alÄ±namadÄ±.\")\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "pc_kamera.release()\n",
    "logitech_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REAL TÄ°ME 2 FARKLI KAMERADAN GÃ–RÃœNTÃœ ALIP OBJECT DETECTÄ°ON YAPAN KODUN  THREAD EKLENMÄ°Åž  VE PERFORMANSI ARTIRILMIÅž  HALÄ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 1 person, 86.8ms\n",
      "Speed: 1.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 76.8ms\n",
      "Speed: 1.0ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 68.8ms\n",
      "Speed: 1.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 71.8ms\n",
      "Speed: 1.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 2 persons, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected objeqct\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, web_camera, window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    start_time_web = time.time()\n",
    "    frame_count_web = 0\n",
    "\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "\n",
    "        if success_pc and success_web:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "\n",
    "            # Concatenate frames horizontallyw\n",
    "            combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "            # Perform object detection on the combined frame\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS for PC Camera\n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display FPS for Web Camera\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the combined frame in the window\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# webcamÄ± bhaÅŸlatma iÅŸlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "#harici kamera baÅŸlatma iÅŸlemi\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "#HazÄ±r eÄŸitilmiÅŸ Yolo modelimi BaÅŸlatma iÅŸlemi.\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "    \n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, web_camera, 'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "\n",
    "combined_thread.start()\n",
    "\n",
    "\n",
    "combined_thread.join()\n",
    "\n",
    "\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralel Ã‡alÄ±ÅŸma Ä°yileÅŸtirme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics YOLOv8.1.9 ðŸš€ Python-3.9.18 torch-2.2.0+cpu CPU (Intel Core(TM) i5-8265U 1.60GHz)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "0: 480x640 1 person, 311.2ms\n",
      "Speed: 4.0ms preprocess, 311.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 239.4ms\n",
      "Speed: 4.0ms preprocess, 239.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 110.7ms\n",
      "Speed: 4.0ms preprocess, 110.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 2.0ms preprocess, 107.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 130.6ms\n",
      "Speed: 3.0ms preprocess, 130.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 118.7ms\n",
      "Speed: 2.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 9 persons, 112.7ms\n",
      "Speed: 2.0ms preprocess, 112.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 3.0ms preprocess, 107.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 108.7ms\n",
      "Speed: 3.2ms preprocess, 108.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 109.7ms\n",
      "Speed: 2.0ms preprocess, 109.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 114.7ms\n",
      "Speed: 5.0ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 118.7ms\n",
      "Speed: 2.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 109.7ms\n",
      "Speed: 5.0ms preprocess, 109.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 115.7ms\n",
      "Speed: 2.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 115.7ms\n",
      "Speed: 5.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 1.0ms preprocess, 107.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 103.8ms\n",
      "Speed: 3.6ms preprocess, 103.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 108.7ms\n",
      "Speed: 3.0ms preprocess, 108.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, web_camera, window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    while True:\n",
    "        start_time_web = time.time()\n",
    "        frame_count_web = 0\n",
    "\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "\n",
    "        if success_pc and success_web:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "\n",
    "            # Concatenate frames horizontally\n",
    "            combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "            # Perform object detection on the combined frame in parallel\n",
    "            pc_thread = threading.Thread(target=detect_objects, args=(frame_pc, model, class_names, 0))\n",
    "            web_thread = threading.Thread(target=detect_objects, args=(frame_web, model, class_names, target_width_pc))\n",
    "            \n",
    "            pc_thread.start()\n",
    "            web_thread.start()\n",
    "\n",
    "            pc_thread.join()\n",
    "            web_thread.join()\n",
    "\n",
    "            # Calculate and display FPS for PC Camera\n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display FPS for Web Camera\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the combined frame in the window\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# webcamÄ± baÅŸlatma iÅŸlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Capture frames and perform object detection for both cameras\n",
    "capture_frames(pc_camera, web_camera, 'Combined Cameras', yolo_model, class_names)\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC VE WEB KAMERALARI AYRI PENCEREDE GÃ–STERME Ä°ÅžLEMÄ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 139.6ms\n",
      "Speed: 3.0ms preprocess, 139.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.6ms\n",
      "Speed: 4.0ms preprocess, 137.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.9ms\n",
      "Speed: 3.0ms preprocess, 132.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.6ms\n",
      "Speed: 1.0ms preprocess, 136.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 257.3ms\n",
      "Speed: 2.0ms preprocess, 257.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 306.5ms\n",
      "Speed: 5.0ms preprocess, 306.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 310.1ms\n",
      "Speed: 4.0ms preprocess, 310.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 317.2ms\n",
      "Speed: 6.0ms preprocess, 317.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 330.2ms\n",
      "Speed: 4.0ms preprocess, 330.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 323.1ms\n",
      "Speed: 4.0ms preprocess, 323.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 345.0ms\n",
      "Speed: 4.0ms preprocess, 345.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 316.0ms\n",
      "Speed: 5.0ms preprocess, 316.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 302.0ms\n",
      "Speed: 3.0ms preprocess, 302.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.9ms\n",
      "Speed: 5.0ms preprocess, 270.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 240.0ms\n",
      "Speed: 3.0ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 246.0ms\n",
      "Speed: 2.0ms preprocess, 246.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 176.0ms\n",
      "Speed: 3.0ms preprocess, 176.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.0ms\n",
      "Speed: 2.0ms preprocess, 173.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.0ms\n",
      "Speed: 2.1ms preprocess, 199.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 231.0ms\n",
      "Speed: 3.0ms preprocess, 231.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 221.0ms\n",
      "Speed: 4.0ms preprocess, 221.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.5ms\n",
      "Speed: 3.0ms preprocess, 218.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 190.0ms\n",
      "Speed: 4.0ms preprocess, 190.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.0ms\n",
      "Speed: 2.0ms preprocess, 175.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.0ms\n",
      "Speed: 2.0ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 1.5ms preprocess, 170.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.0ms\n",
      "Speed: 3.0ms preprocess, 173.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 253.0ms\n",
      "Speed: 2.0ms preprocess, 253.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 306.0ms\n",
      "Speed: 2.0ms preprocess, 306.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 311.0ms\n",
      "Speed: 4.0ms preprocess, 311.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 328.0ms\n",
      "Speed: 4.0ms preprocess, 328.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 312.0ms\n",
      "Speed: 5.0ms preprocess, 312.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 332.1ms\n",
      "Speed: 5.0ms preprocess, 332.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 318.0ms\n",
      "Speed: 5.0ms preprocess, 318.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 305.0ms\n",
      "Speed: 4.0ms preprocess, 305.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 274.0ms\n",
      "Speed: 4.0ms preprocess, 274.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 217.0ms\n",
      "Speed: 4.0ms preprocess, 217.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n",
      "Speed: 2.0ms preprocess, 162.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.1ms\n",
      "Speed: 2.0ms preprocess, 168.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 168.3ms\n",
      "Speed: 1.5ms preprocess, 168.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.0ms\n",
      "Speed: 2.0ms preprocess, 134.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.4ms\n",
      "Speed: 2.0ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.0ms\n",
      "Speed: 1.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 117.6ms\n",
      "Speed: 1.0ms preprocess, 117.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.9ms\n",
      "Speed: 1.0ms preprocess, 119.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.7ms\n",
      "Speed: 2.0ms preprocess, 124.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.7ms\n",
      "Speed: 2.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 112.7ms\n",
      "Speed: 1.0ms preprocess, 112.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.3ms\n",
      "Speed: 2.0ms preprocess, 126.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 261.9ms\n",
      "Speed: 1.0ms preprocess, 261.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 251.3ms\n",
      "Speed: 3.0ms preprocess, 251.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 235.4ms\n",
      "Speed: 3.0ms preprocess, 235.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 239.4ms\n",
      "Speed: 3.0ms preprocess, 239.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 237.4ms\n",
      "Speed: 4.0ms preprocess, 237.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.8ms\n",
      "Speed: 3.0ms preprocess, 248.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.8ms\n",
      "Speed: 2.0ms preprocess, 122.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.7ms\n",
      "Speed: 2.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 1.0ms preprocess, 107.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.7ms\n",
      "Speed: 1.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.7ms\n",
      "Speed: 1.0ms preprocess, 126.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, window_name, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            #target_width = 480\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the frame in the window\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# webcamÄ± baÅŸlatma iÅŸlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_2 = YOLO(\"yolo-Weights/yolov8n2.pt\")\n",
    "    \n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# AyrÄ± ayrÄ± pencereler iÃ§in isimler\n",
    "window_name_pc = 'PC Camera'\n",
    "window_name_web = 'Web Camera'\n",
    "\n",
    "# Create threads for capturing frames and performing object detection for both cameras\n",
    "pc_thread = threading.Thread(target=capture_frames, args=(pc_camera, window_name_pc, yolo_model, class_names))\n",
    "web_thread = threading.Thread(target=capture_frames, args=(web_camera, window_name_web, yolo_model_2, class_names))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Wait for the threads to finish\n",
    "pc_thread.join()\n",
    "web_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 FARKLI KAMERADAN GÃ–RÃœNTÃœ ALMA VE DETECTÄ°ON Ä°ÅžLEMÄ° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 160x640 2 persons, 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 124.2ms\n",
      "Speed: 2.0ms preprocess, 124.2ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 121.7ms\n",
      "Speed: 3.0ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 54.9ms\n",
      "Speed: 1.0ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 53.9ms\n",
      "Speed: 1.0ms preprocess, 53.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 88.8ms\n",
      "Speed: 1.0ms preprocess, 88.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 68.8ms\n",
      "Speed: 1.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 53.9ms\n",
      "Speed: 1.0ms preprocess, 53.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.8ms\n",
      "Speed: 1.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.4ms\n",
      "Speed: 1.0ms preprocess, 61.4ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 57.8ms\n",
      "Speed: 2.0ms preprocess, 57.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 66.8ms\n",
      "Speed: 1.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 68.8ms\n",
      "Speed: 1.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 60.8ms\n",
      "Speed: 1.0ms preprocess, 60.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 55.8ms\n",
      "Speed: 1.0ms preprocess, 55.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 120.7ms\n",
      "Speed: 2.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 113.7ms\n",
      "Speed: 2.0ms preprocess, 113.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 109.7ms\n",
      "Speed: 3.0ms preprocess, 109.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 108.7ms\n",
      "Speed: 3.0ms preprocess, 108.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 114.3ms\n",
      "Speed: 2.0ms preprocess, 114.3ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 118.7ms\n",
      "Speed: 2.0ms preprocess, 118.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 120.7ms\n",
      "Speed: 2.0ms preprocess, 120.7ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 125.3ms\n",
      "Speed: 3.0ms preprocess, 125.3ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 50.6ms\n",
      "Speed: 0.8ms preprocess, 50.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.5ms\n",
      "Speed: 1.0ms preprocess, 59.5ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.8ms\n",
      "Speed: 1.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.8ms\n",
      "Speed: 1.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.8ms\n",
      "Speed: 2.0ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 55.6ms\n",
      "Speed: 2.0ms preprocess, 55.6ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.4ms\n",
      "Speed: 1.0ms preprocess, 58.4ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 2.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 89.8ms\n",
      "Speed: 1.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 67.8ms\n",
      "Speed: 1.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.8ms\n",
      "Speed: 1.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 53.9ms\n",
      "Speed: 1.0ms preprocess, 53.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.8ms\n",
      "Speed: 1.0ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 98.7ms\n",
      "Speed: 2.0ms preprocess, 98.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 115.7ms\n",
      "Speed: 2.0ms preprocess, 115.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 118.7ms\n",
      "Speed: 3.0ms preprocess, 118.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 113.7ms\n",
      "Speed: 2.0ms preprocess, 113.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 130.7ms\n",
      "Speed: 3.0ms preprocess, 130.7ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 144.6ms\n",
      "Speed: 4.0ms preprocess, 144.6ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 152.6ms\n",
      "Speed: 3.0ms preprocess, 152.6ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 117.7ms\n",
      "Speed: 3.0ms preprocess, 117.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 108.7ms\n",
      "Speed: 2.0ms preprocess, 108.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 65.8ms\n",
      "Speed: 4.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 55.9ms\n",
      "Speed: 1.0ms preprocess, 55.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.9ms\n",
      "Speed: 1.0ms preprocess, 56.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.8ms\n",
      "Speed: 2.0ms preprocess, 56.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.8ms\n",
      "Speed: 1.0ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 54.9ms\n",
      "Speed: 2.0ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 69.8ms\n",
      "Speed: 1.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 91.3ms\n",
      "Speed: 13.0ms preprocess, 91.3ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 86.8ms\n",
      "Speed: 1.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 66.8ms\n",
      "Speed: 1.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 63.8ms\n",
      "Speed: 1.0ms preprocess, 63.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.8ms\n",
      "Speed: 1.0ms preprocess, 59.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 143.6ms\n",
      "Speed: 38.9ms preprocess, 143.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 123.7ms\n",
      "Speed: 2.0ms preprocess, 123.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 135.6ms\n",
      "Speed: 3.0ms preprocess, 135.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 137.6ms\n",
      "Speed: 3.0ms preprocess, 137.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 136.6ms\n",
      "Speed: 3.0ms preprocess, 136.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 145.1ms\n",
      "Speed: 3.0ms preprocess, 145.1ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 143.6ms\n",
      "Speed: 2.0ms preprocess, 143.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 63.4ms\n",
      "Speed: 1.0ms preprocess, 63.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 57.8ms\n",
      "Speed: 1.0ms preprocess, 57.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.3ms\n",
      "Speed: 1.0ms preprocess, 62.3ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 55.4ms\n",
      "Speed: 1.0ms preprocess, 55.4ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.3ms\n",
      "Speed: 1.0ms preprocess, 61.3ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 66.8ms\n",
      "Speed: 1.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.9ms\n",
      "Speed: 1.0ms preprocess, 56.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 81.8ms\n",
      "Speed: 1.0ms preprocess, 81.8ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 113.7ms\n",
      "Speed: 3.0ms preprocess, 113.7ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 143.1ms\n",
      "Speed: 3.0ms preprocess, 143.1ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 142.6ms\n",
      "Speed: 2.0ms preprocess, 142.6ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 128.7ms\n",
      "Speed: 4.0ms preprocess, 128.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 155.6ms\n",
      "Speed: 3.0ms preprocess, 155.6ms inference, 4.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 168.5ms\n",
      "Speed: 2.0ms preprocess, 168.5ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 129.7ms\n",
      "Speed: 3.0ms preprocess, 129.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.8ms\n",
      "Speed: 3.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.8ms\n",
      "Speed: 1.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.7ms\n",
      "Speed: 1.0ms preprocess, 52.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 56.9ms\n",
      "Speed: 1.0ms preprocess, 56.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 55.9ms\n",
      "Speed: 1.0ms preprocess, 55.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 44.9ms\n",
      "Speed: 1.0ms preprocess, 44.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 49.9ms\n",
      "Speed: 1.0ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 60.9ms\n",
      "Speed: 2.0ms preprocess, 60.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 53.9ms\n",
      "Speed: 1.0ms preprocess, 53.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 54.9ms\n",
      "Speed: 1.0ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 59.8ms\n",
      "Speed: 1.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.9ms\n",
      "Speed: 2.0ms preprocess, 52.9ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 101.7ms\n",
      "Speed: 3.0ms preprocess, 101.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 106.7ms\n",
      "Speed: 3.0ms preprocess, 106.7ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 108.2ms\n",
      "Speed: 3.0ms preprocess, 108.2ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 125.4ms\n",
      "Speed: 2.0ms preprocess, 125.4ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 118.1ms\n",
      "Speed: 3.0ms preprocess, 118.1ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 2 persons, 110.1ms\n",
      "Speed: 2.0ms preprocess, 110.1ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            \n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "       \n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def capture_frames(pc_camera, web_camera,phone_camera , window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    start_time_web = time.time()\n",
    "    frame_count_web = 0\n",
    "    \n",
    "    start_time_phone = time.time()\n",
    "    frame_count_phone = 0\n",
    "\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "        success_phone_camera, frame_phone = phone_camera.read()\n",
    "\n",
    "        if success_pc and success_web and success_phone_camera:\n",
    "            \n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            height_phone,with_phone,_ = frame_phone.shape\n",
    "            \n",
    "            \n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "            target_width_phone= int(target_height * (with_phone / height_phone))\n",
    "            \n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "            frame_phone= cv2.resize(frame_phone, (target_width_phone, target_height))\n",
    "\n",
    "        \n",
    "            combined_frame = np.hstack((frame_pc, frame_web,frame_phone))\n",
    "\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "          \n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "            frame_count_phone += 1\n",
    "            elapsed_time_phone = time.time() - start_time_phone\n",
    "            fps_phone = frame_count_phone / elapsed_time_phone\n",
    "            cv2.putText(combined_frame, f\"FPS PHONE: {fps_phone:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "            combined_frame=cv2.resize(combined_frame, (1366, 768))\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "            #cv2.resizeWindow(window_name, 800, 600, combined_frame)\n",
    "            #cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Laptop kamera baÅŸlatma iÅŸlemi\n",
    "pc_camera = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Web kamera baÅŸlatma iÅŸlemi\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# telefon kamerasÄ±nÄ± baÅŸlatmak iÃ§in\n",
    "Phone_Camera_Adress = \"http://172.16.3.109:8080/video\" \n",
    "phone_camera= cv2.VideoCapture(Phone_Camera_Adress) #Bekleme sÃ¼resini azaltmak iÃ§in kullanÄ±lÄ±r.\n",
    "phone_camera.set(3, 640)\n",
    "phone_camera.set(4, 480)\n",
    "\n",
    "#HazÄ±r eÄŸitilmiÅŸ Yolo modelimi BaÅŸlatma iÅŸlemi.\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "    \n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, web_camera,phone_camera ,'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "\n",
    "combined_thread.start()\n",
    "\n",
    "\n",
    "combined_thread.join()\n",
    "\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "phone_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FARKLI THREADLERLE FARKLI PENCERELERDE OBJECT DETECTION Ä°ÅžLEMÄ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov3u.pt to 'yolo-Weights\\yolov3u.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 16.0M/198M [03:48<43:31, 73.2kB/s]  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m yolo_model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo-Weights/yolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m yolo_model_2 \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo-Weights/yolov8n2.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m yolo_model_3 \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolo-Weights/yolov3u.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m model_4\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo-Weights\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mssd_mobilenet_v2_oid_v4.config\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicycle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotorbike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maeroplane\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruck\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraffic light\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfire hydrant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop sign\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparking meter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbench\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbird\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    104\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msheep\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melephant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzebra\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiraffe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumbrella\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrowave\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moven\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoaster\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msink\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefrigerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscissors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteddy bear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhair drier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoothbrush\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\ultralytics\\engine\\model.py:134\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\ultralytics\\engine\\model.py:215\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    213\u001b[0m suffix \u001b[38;5;241m=\u001b[39m Path(weights)\u001b[38;5;241m.\u001b[39msuffix\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:709\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    710\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:634\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    628\u001b[0m         {\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m         }\n\u001b[0;32m    633\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\serialization.py:1005\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1003\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1004\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1005\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[0;32m   1007\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1008\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1009\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bedir\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\serialization.py:457\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected objeqct\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, web_camera, window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    start_time_web = time.time()\n",
    "    frame_count_web = 0\n",
    "\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "\n",
    "        if success_pc and success_web:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "\n",
    "            # Concatenate frames horizontally\n",
    "            combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "            # Perform object detection on the combined frame\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS for PC Camera\n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display FPS for Web Camera\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the combined frame in the window\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# webcamÄ± bhaÅŸlatma iÅŸlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "#harici kamera baÅŸlatma iÅŸlemi\n",
    "web_camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "#HazÄ±r eÄŸitilmiÅŸ Yolo modelimi BaÅŸlatma iÅŸlemi.\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_2 = YOLO(\"yolo-Weights/yolov8n2.pt\")\n",
    "yolo_model_3 = YOLO(\"yolo-Weights/yolov3u.pt\")\n",
    "model_4= \"yolo-Weights\\ssd_mobilenet_v2_oid_v4.config\"\n",
    "    \n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "thread_pc = threading.Thread(target=capture_frames, args=(pc_camera, web_camera, 'Combined Cameras', yolo_model, class_names))\n",
    "thread_web=  threading.Thread(target=capture_frames, args=(pc_camera, web_camera, 'Combined Cameras', yolo_model_2, class_names))\n",
    "\n",
    "thread_pc.start()\n",
    "thread_web.start()\n",
    "\n",
    "thread_pc.join()\n",
    "thread_web.join()\n",
    "\n",
    "\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                \n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id,cv2.CAP_DSHOW)\n",
    "        self.camera.set(3, 640)\n",
    "        self.camera.set(4, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "class MultiCameraObjectDetection:\n",
    "    def __init__(self, pc_camera_id, web_camera_id, detector, window_name):\n",
    "        self.pc_camera = Camera(pc_camera_id)\n",
    "        self.web_camera = Camera(web_camera_id)\n",
    "        self.detector = detector\n",
    "        self.window_name = window_name\n",
    "\n",
    "    def capture_frames(self):\n",
    "        start_time_pc = time.time()\n",
    "        frame_count_pc = 0\n",
    "\n",
    "        start_time_web = time.time()\n",
    "        frame_count_web = 0\n",
    "\n",
    "        while True:\n",
    "            success_pc, frame_pc = self.pc_camera.read_frame()\n",
    "            success_web, frame_web = self.web_camera.read_frame()\n",
    "\n",
    "            if success_pc and success_web:\n",
    "              \n",
    "                height_pc, width_pc, _ = frame_pc.shape\n",
    "                height_web, width_web, _ = frame_web.shape\n",
    "                target_width_pc = int(height_pc * (width_pc / height_pc))\n",
    "                target_width_web = int(height_web * (width_web / height_web))\n",
    "\n",
    "                frame_pc = cv2.resize(frame_pc, (target_width_pc, height_pc))\n",
    "                frame_web = cv2.resize(frame_web, (target_width_web, height_web))\n",
    "\n",
    "                combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "              \n",
    "                self.detector.detect_objects(combined_frame, offset_x=0)\n",
    "\n",
    "             \n",
    "                frame_count_pc += 1\n",
    "                elapsed_time_pc = time.time() - start_time_pc\n",
    "                fps_pc = frame_count_pc / elapsed_time_pc\n",
    "                cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "              \n",
    "                frame_count_web += 1\n",
    "                elapsed_time_web = time.time() - start_time_web\n",
    "                fps_web = frame_count_web / elapsed_time_web\n",
    "                cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "                cv2.imshow(self.window_name, combined_frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.pc_camera.release()\n",
    "        self.web_camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "\n",
    "multi_cam_detector = MultiCameraObjectDetection(0, 1, detector, 'Combined Cameras')\n",
    "combined_thread = threading.Thread(target=multi_cam_detector.capture_frames)\n",
    "\n",
    "combined_thread.start()\n",
    "combined_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
